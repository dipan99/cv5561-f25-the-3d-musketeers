{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3db5968",
   "metadata": {},
   "source": [
    "### Extract Sample Images for Point Cloud Algorithm\n",
    "Get images from the \"imgs\" folder for 3D reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63f5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "# Configuration\n",
    "imgs_dir = Path('./imgs')\n",
    "output_dir = Path('./sample_images')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Get all images from imgs folder\n",
    "image_files = sorted(glob.glob(str(imgs_dir / '*.png')))\n",
    "num_samples = min(5, len(image_files))  # Use up to 5 images\n",
    "\n",
    "print(f\"=== Loading {num_samples} Images from imgs/ folder ===\\n\")\n",
    "print(f\"Found {len(image_files)} total images\\n\")\n",
    "\n",
    "# Store image data (no camera poses available for these images)\n",
    "sample_data = []\n",
    "\n",
    "for i, img_path in enumerate(image_files[:num_samples]):\n",
    "    img_path = Path(img_path)\n",
    "    \n",
    "    # Copy to output directory with standardized name\n",
    "    output_path = output_dir / f\"image_{i}.png\"\n",
    "    shutil.copy(img_path, output_path)\n",
    "    \n",
    "    # Store info\n",
    "    sample_data.append({\n",
    "        'index': i,\n",
    "        'original_name': img_path.name,\n",
    "        'color_path': output_path,\n",
    "        'pose_matrix': None  # No poses available for custom images\n",
    "    })\n",
    "    \n",
    "    print(f\"✓ Image {i}: {img_path.name}\")\n",
    "    print(f\"  Saved to: {output_path}\")\n",
    "\n",
    "print(f\"\\n✓ All images copied to: {output_dir}/\")\n",
    "print(f\"\\nYou now have:\")\n",
    "print(f\"  - {num_samples} RGB images (image_0.png to image_{num_samples-1}.png)\")\n",
    "print(f\"\\n⚠ Note: No camera poses available - will estimate from images using SfM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d9ed18",
   "metadata": {},
   "source": [
    "### Next Steps: Point Cloud Reconstruction\n",
    "\n",
    "Images loaded from custom folder - camera poses will be estimated!\n",
    "\n",
    "**Reconstruction Pipeline:**\n",
    "1. Extract SIFT features from each image\n",
    "2. Match features between consecutive image pairs\n",
    "3. Estimate camera poses using Essential Matrix\n",
    "4. Triangulate 3D points from correspondences\n",
    "5. Build colored point cloud\n",
    "\n",
    "**Camera Intrinsics:**\n",
    "- Estimated from image dimensions\n",
    "- Assumes typical consumer camera\n",
    "- Focal length ≈ 1.2 × max(width, height)\n",
    "\n",
    "For better results, consider camera calibration first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62137461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have camera poses\n",
    "has_poses = sample_data[0]['pose_matrix'] is not None\n",
    "\n",
    "if has_poses:\n",
    "    # Display camera pose information\n",
    "    print(\"=== Camera Pose Matrices ===\\n\")\n",
    "    print(\"Each 4x4 matrix represents camera position and orientation in 3D space\")\n",
    "    print(\"Format: [R | t] where R is 3x3 rotation, t is 3x1 translation\\n\")\n",
    "\n",
    "    for i, data in enumerate(sample_data):\n",
    "        print(f\"--- Image {i} (frame {data['frame']}) ---\")\n",
    "        print(data['pose_matrix'])\n",
    "        print(f\"Camera position (x, y, z): [{data['pose_matrix'][0,3]:.3f}, {data['pose_matrix'][1,3]:.3f}, {data['pose_matrix'][2,3]:.3f}]\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"=== No Camera Poses Available ===\\n\")\n",
    "    print(\"Using custom images from imgs/ folder.\")\n",
    "    print(\"Camera poses will need to be estimated using Structure from Motion (SfM).\")\n",
    "    print(\"\\nFor point cloud reconstruction, we'll use:\")\n",
    "    print(\"  1. Feature matching between images\")\n",
    "    print(\"  2. Essential matrix estimation\")\n",
    "    print(\"  3. Camera pose recovery\")\n",
    "    print(\"  4. Triangulation of 3D points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2b1fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the selected images\n",
    "fig, axes = plt.subplots(1, len(sample_data), figsize=(4*len(sample_data), 4))\n",
    "\n",
    "# Handle case where there's only 1 image\n",
    "if len(sample_data) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, data in enumerate(sample_data):\n",
    "    img = Image.open(data['color_path'])\n",
    "    axes[i].imshow(img)\n",
    "    title = f\"Image {i}\\n{data['original_name']}\"\n",
    "    axes[i].set_title(title)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'sample_overview.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved visualization to sample_images/sample_overview.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c718127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save point cloud to file\n",
    "output_ply = output_dir / 'point_cloud.ply'\n",
    "\n",
    "# Write PLY file\n",
    "with open(output_ply, 'w') as f:\n",
    "    f.write(\"ply\\n\")\n",
    "    f.write(\"format ascii 1.0\\n\")\n",
    "    f.write(f\"element vertex {len(point_cloud)}\\n\")\n",
    "    f.write(\"property float x\\n\")\n",
    "    f.write(\"property float y\\n\")\n",
    "    f.write(\"property float z\\n\")\n",
    "    f.write(\"property uchar red\\n\")\n",
    "    f.write(\"property uchar green\\n\")\n",
    "    f.write(\"property uchar blue\\n\")\n",
    "    f.write(\"end_header\\n\")\n",
    "    \n",
    "    for i in range(len(point_cloud)):\n",
    "        x, y, z = point_cloud[i]\n",
    "        r, g, b = (point_colors[i] * 255).astype(int)\n",
    "        f.write(f\"{x} {y} {z} {r} {g} {b}\\n\")\n",
    "\n",
    "print(f\"✓ Point cloud saved to: {output_ply}\")\n",
    "print(f\"\\nPoint cloud statistics:\")\n",
    "print(f\"  Total points: {len(point_cloud)}\")\n",
    "print(f\"  X range: [{point_cloud[:, 0].min():.3f}, {point_cloud[:, 0].max():.3f}]\")\n",
    "print(f\"  Y range: [{point_cloud[:, 1].min():.3f}, {point_cloud[:, 1].max():.3f}]\")\n",
    "print(f\"  Z range: [{point_cloud[:, 2].min():.3f}, {point_cloud[:, 2].max():.3f}]\")\n",
    "print(f\"\\nYou can open the .ply file in MeshLab, CloudCompare, or Blender!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the point cloud\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Downsample for visualization\n",
    "max_points = 10000\n",
    "if len(point_cloud) > max_points:\n",
    "    indices = np.random.choice(len(point_cloud), max_points, replace=False)\n",
    "    plot_points = point_cloud[indices]\n",
    "    plot_colors = point_colors[indices]\n",
    "else:\n",
    "    plot_points = point_cloud\n",
    "    plot_colors = point_colors\n",
    "\n",
    "# Plot\n",
    "ax.scatter(plot_points[:, 0], plot_points[:, 1], plot_points[:, 2],\n",
    "           c=plot_colors, marker='.', s=1, alpha=0.6)\n",
    "\n",
    "ax.set_xlabel('X (meters)')\n",
    "ax.set_ylabel('Y (meters)')\n",
    "ax.set_zlabel('Z (meters)')\n",
    "ax.set_title(f'3D Point Cloud from {len(sample_data)} Images\\n({len(point_cloud)} points)')\n",
    "\n",
    "# Set equal aspect ratio\n",
    "max_range = np.array([plot_points[:, 0].max() - plot_points[:, 0].min(),\n",
    "                      plot_points[:, 1].max() - plot_points[:, 1].min(),\n",
    "                      plot_points[:, 2].max() - plot_points[:, 2].min()]).max() / 2.0\n",
    "\n",
    "mid_x = (plot_points[:, 0].max() + plot_points[:, 0].min()) * 0.5\n",
    "mid_y = (plot_points[:, 1].max() + plot_points[:, 1].min()) * 0.5\n",
    "mid_z = (plot_points[:, 2].max() + plot_points[:, 2].min()) * 0.5\n",
    "\n",
    "ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "plt.savefig(output_dir / 'point_cloud.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Point cloud visualization saved to {output_dir / 'point_cloud.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9889eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build point cloud from all image pairs\n",
    "print(\"=== Building Point Cloud ===\\n\")\n",
    "\n",
    "all_points_3d = []\n",
    "all_colors = []\n",
    "\n",
    "has_poses = sample_data[0]['pose_matrix'] is not None\n",
    "\n",
    "# First camera is at origin\n",
    "if not has_poses:\n",
    "    # Initialize first pose as identity (at origin)\n",
    "    sample_data[0]['pose_matrix'] = np.eye(4)\n",
    "\n",
    "# Process consecutive image pairs\n",
    "for i in range(len(sample_data) - 1):\n",
    "    img1_path = sample_data[i]['color_path']\n",
    "    img2_path = sample_data[i + 1]['color_path']\n",
    "    \n",
    "    # Load images\n",
    "    img1 = np.array(Image.open(img1_path))\n",
    "    img2 = np.array(Image.open(img2_path))\n",
    "    \n",
    "    print(f\"Processing pair: Image {i} <-> Image {i+1}\")\n",
    "    \n",
    "    # Extract and match features\n",
    "    pts1, pts2, matches = extract_and_match_features(img1, img2)\n",
    "    \n",
    "    if len(pts1) < 8:\n",
    "        print(f\"  ⚠ Not enough matches ({len(pts1)}), skipping\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"  Found {len(matches)} good matches\")\n",
    "    \n",
    "    if has_poses:\n",
    "        # Use ground truth poses\n",
    "        pose1 = sample_data[i]['pose_matrix']\n",
    "        pose2 = sample_data[i + 1]['pose_matrix']\n",
    "    else:\n",
    "        # Estimate relative pose using Essential matrix\n",
    "        E, mask = cv2.findEssentialMat(pts1, pts2, K, method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
    "        _, R, t, mask = cv2.recoverPose(E, pts1, pts2, K)\n",
    "        \n",
    "        # Build pose matrix for second camera\n",
    "        pose1 = sample_data[i]['pose_matrix']\n",
    "        pose2 = np.eye(4)\n",
    "        pose2[:3, :3] = R\n",
    "        pose2[:3, 3] = t.flatten()\n",
    "        \n",
    "        # Compose with previous pose (chain transformations)\n",
    "        sample_data[i + 1]['pose_matrix'] = pose2 @ pose1\n",
    "        \n",
    "        print(f\"  Estimated relative pose:\")\n",
    "        print(f\"    Rotation magnitude: {np.linalg.norm(R - np.eye(3)):.3f}\")\n",
    "        print(f\"    Translation: [{t[0,0]:.3f}, {t[1,0]:.3f}, {t[2,0]:.3f}]\")\n",
    "    \n",
    "    # Get final poses\n",
    "    pose1 = sample_data[i]['pose_matrix']\n",
    "    pose2 = sample_data[i + 1]['pose_matrix']\n",
    "    \n",
    "    # Create projection matrices: P = K * [R | t]\n",
    "    P1 = K @ pose1[:3, :]  # 3x4 projection matrix\n",
    "    P2 = K @ pose2[:3, :]\n",
    "    \n",
    "    # Triangulate points\n",
    "    points_3d = triangulate_points(pts1, pts2, P1, P2)\n",
    "    \n",
    "    # Get colors from first image\n",
    "    colors = []\n",
    "    for pt in pts1:\n",
    "        x, y = int(pt[0]), int(pt[1])\n",
    "        if 0 <= x < img1.shape[1] and 0 <= y < img1.shape[0]:\n",
    "            colors.append(img1[y, x] / 255.0)\n",
    "        else:\n",
    "            colors.append([0.5, 0.5, 0.5])\n",
    "    \n",
    "    colors = np.array(colors)\n",
    "    \n",
    "    # Filter outliers (points too far from camera)\n",
    "    valid_mask = np.abs(points_3d).max(axis=1) < 10.0  # within 10 meters\n",
    "    points_3d_filtered = points_3d[valid_mask]\n",
    "    colors_filtered = colors[valid_mask]\n",
    "    \n",
    "    print(f\"  Triangulated {len(points_3d_filtered)} valid 3D points\")\n",
    "    \n",
    "    all_points_3d.append(points_3d_filtered)\n",
    "    all_colors.append(colors_filtered)\n",
    "\n",
    "# Combine all points\n",
    "if len(all_points_3d) > 0:\n",
    "    point_cloud = np.vstack(all_points_3d)\n",
    "    point_colors = np.vstack(all_colors)\n",
    "    print(f\"\\n✓ Total point cloud size: {len(point_cloud)} points\")\n",
    "else:\n",
    "    print(\"\\n✗ No points generated. Check image matching quality.\")\n",
    "    point_cloud = np.zeros((0, 3))\n",
    "    point_colors = np.zeros((0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0237222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulate_points(pts1, pts2, P1, P2):\n",
    "    \"\"\"Triangulate 3D points from 2D correspondences and projection matrices\"\"\"\n",
    "    # Convert to homogeneous coordinates\n",
    "    pts1_norm = cv2.undistortPoints(pts1.reshape(-1, 1, 2), K, None)\n",
    "    pts2_norm = cv2.undistortPoints(pts2.reshape(-1, 1, 2), K, None)\n",
    "    \n",
    "    # Triangulate\n",
    "    points_4d = cv2.triangulatePoints(P1, P2, pts1_norm, pts2_norm)\n",
    "    \n",
    "    # Convert from homogeneous to 3D\n",
    "    points_3d = points_4d[:3] / points_4d[3]\n",
    "    \n",
    "    return points_3d.T\n",
    "\n",
    "print(\"Triangulation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_match_features(img1, img2):\n",
    "    \"\"\"Extract SIFT features and match between two images\"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Create SIFT detector\n",
    "    sift = cv2.SIFT_create(nfeatures=2000)\n",
    "    \n",
    "    # Detect and compute\n",
    "    kp1, des1 = sift.detectAndCompute(gray1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(gray2, None)\n",
    "    \n",
    "    # Match features using FLANN\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    # Apply Lowe's ratio test\n",
    "    good_matches = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    \n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            good_matches.append(m)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "    \n",
    "    return np.float32(pts1), np.float32(pts2), good_matches\n",
    "\n",
    "print(\"Feature extraction and matching function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d45ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load first image to get dimensions\n",
    "first_img = Image.open(sample_data[0]['color_path'])\n",
    "img_width, img_height = first_img.size\n",
    "\n",
    "# Estimate camera intrinsics (typical for consumer cameras)\n",
    "# Focal length estimated as 1.2 * max(width, height)\n",
    "focal_length = 1.2 * max(img_width, img_height)\n",
    "cx, cy = img_width / 2.0, img_height / 2.0  # principal point at center\n",
    "\n",
    "K = np.array([\n",
    "    [focal_length, 0, cx],\n",
    "    [0, focal_length, cy],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "print(\"=== Camera Intrinsic Matrix (Estimated) ===\")\n",
    "print(K)\n",
    "print(f\"\\nImage resolution: {img_width}x{img_height}\")\n",
    "print(f\"Estimated focal length: {focal_length:.1f}px\")\n",
    "print(f\"Principal point: ({cx:.1f}, {cy:.1f})\")\n",
    "print(\"\\nNote: These are typical estimates. Actual calibration would improve results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa634d9",
   "metadata": {},
   "source": [
    "### Create Point Cloud from Images\n",
    "Using feature matching and triangulation with known camera poses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
